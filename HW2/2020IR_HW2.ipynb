{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75t8NMTSJKHl"
   },
   "source": [
    "# **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f5lS36UuJEBG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from numpy import dot\n",
    "import math\n",
    "\n",
    "file_path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVsydLPWJNXN"
   },
   "source": [
    "# **Read File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list\n",
    "query_list = []\n",
    "doc_list = []\n",
    "all_query = []\n",
    "all_doc = []\n",
    "query_data = [] ##split的結果\n",
    "query_voc_dict = {}\n",
    "\n",
    "##query list\n",
    "with open(file_path+'query_list.txt','r') as f:\n",
    "    query = f.readlines()\n",
    "    for i in range(len(query)):\n",
    "        query_list.append(query[i].strip('\\n'))\n",
    "\n",
    "## doc list\n",
    "with open(file_path+'doc_list.txt','r') as f:\n",
    "    doc = f.readlines()\n",
    "    for i in range(len(doc)):\n",
    "        doc_list.append(doc[i].strip('\\n'))\n",
    "##all query 先讀進來建voc\n",
    "for i in range(len(query_list)):\n",
    "    with open(file_path+'./queries/'+str(query_list[i])+'.txt','r') as f:\n",
    "        q_content = f.readlines()\n",
    "        all_query.append(q_content)\n",
    "        q_content_split = q_content[0].split()  ##split string\n",
    "        query_data.append(q_content_split)\n",
    "        for j in q_content_split: ##建字典\n",
    "            query_voc_dict[j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "6mnLO5YsJJWj",
    "outputId": "5346a0eb-5089-4ee1-ae0d-70d838b873e7"
   },
   "outputs": [],
   "source": [
    "\n",
    "## 各個dict&matrix\n",
    "idf_dict = query_voc_dict.copy()\n",
    "query_tf_matrix = np.zeros((50,123))\n",
    "doc_tf_matrix = np.zeros((4191,123))\n",
    "## doc length\n",
    "avg_doc_len = 0\n",
    "\n",
    "##query的tf\n",
    "for i in range(len(query_data)):\n",
    "    query_dict = query_voc_dict.copy()\n",
    "    for j in query_data[i]:\n",
    "        if j in query_voc_dict:\n",
    "            query_dict[j] += 1\n",
    "    query_tf_matrix[i] = np.array(list(query_dict.values()))\n",
    "\n",
    "## all doc idf跟tf \n",
    "for i in range(len(doc_list)):\n",
    "    doc_dict = query_voc_dict.copy() ##複製一個只有 key的\n",
    "    update = {} ##拿來判斷是否用過\n",
    "    with open(file_path+'./docs/'+str(doc_list[i])+'.txt','r') as f:\n",
    "        d_content = f.readlines()\n",
    "        \n",
    "        if(len(d_content)!=0): ##避免那篇有問題的\n",
    "            d_content_split = d_content[0].split() ## split string\n",
    "            avg_doc_len += len(d_content[0])\n",
    "            for j in d_content_split:   ##all word\n",
    "                if j in query_voc_dict: ## if in dict\n",
    "                    doc_dict[j] += 1 ##doc的 tf\n",
    "                    if (not(j in update)):\n",
    "                        idf_dict[j]+=1\n",
    "                        update[j] = 0 ##used\n",
    "        doc_tf_matrix[i]= np.array(list(doc_dict.values())) ##得到tf值矩陣\n",
    "        all_doc.append(d_content)\n",
    "\n",
    "avg_doc_len /= len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(doc_tf_matrix,query_tf_matrix,idf_dict):\n",
    "    K1 = 3.5\n",
    "    K3 = 1\n",
    "    b = 0.75\n",
    "    N = len(all_doc) ##總共文章\n",
    "    all_ans_list = []\n",
    "    query_ans_list = [] ## not sort\n",
    "    idf_score = np.array(list(idf_dict.values()))\n",
    "    query_tf = np.zeros((50,123))\n",
    "    doc_tf = np.zeros((4191,123))\n",
    "    # doc_T = doc.T ##Transpose\n",
    "    for i in range(doc_tf_matrix.shape[0]):\n",
    "        for j in range(doc_tf_matrix.shape[1]):\n",
    "            if len(all_doc[i]) != 0:\n",
    "                tf_dot = doc_tf_matrix[i][j] / (1 - b + b * (len(all_doc[i][0]) / avg_doc_len))\n",
    "                tf = ((K1 + 1) * tf_dot / (K1 + tf_dot))\n",
    "                if tf > 0:\n",
    "                    tf += 0.2\n",
    "                doc_tf[i][j] = tf\n",
    "    # print(doc_tf[1])\n",
    "    for i in range(query_tf_matrix.shape[0]):\n",
    "        for j in range(query_tf_matrix.shape[1]):\n",
    "            tf = (K3 + 1) * query_tf_matrix[i][j] / (K3 + query_tf_matrix[i][j])\n",
    "            query_tf_idf = tf * math.log((N - idf_score[j] + 0.5) / (idf_score[j] + 0.5)) * math.log((N - idf_score[j] + 0.5) / (idf_score[j] + 0.5)) \n",
    "            query_tf[i][j] = query_tf_idf\n",
    "        result = np.matmul(doc_tf,query_tf[i])\n",
    "        query_ans_list.append(result)\n",
    "    for i in range(len(query_ans_list)): ##50個query\n",
    "    #     ans_list = []\n",
    "        ans_list = sorted(range(len(query_ans_list[i])),reverse = True ,key = lambda k : query_ans_list[i][k]) \n",
    "        result_list = []\n",
    "        for j in ans_list:\n",
    "            result_list.append(doc_list[j])\n",
    "        all_ans_list.append(result_list)\n",
    "    return all_ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_list = BM25(doc_tf_matrix,query_tf_matrix,idf_dict)\n",
    "\n",
    "save_path = './'\n",
    "with open(save_path+'hw2_result_BM25.txt','w') as f:\n",
    "    f.write('Query,RetrievedDocuments\\n')\n",
    "    for i in range(50): \n",
    "        f.write(query_list[i])\n",
    "        f.write(',')\n",
    "        for j in range(len(ans_list[0])):\n",
    "            f.write(ans_list[i][j])\n",
    "            f.write(' ')\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1sbDLcK_i1DA"
   ],
   "name": "2020IR_HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
